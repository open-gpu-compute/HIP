

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Frequently Asked Questions (FAQ) &mdash; HIP  documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/custom.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Repository Information" href="repository_information.html" />
    <link rel="prev" title="Comparison with CUDA and other compute APIs" href="comparison.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> HIP
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="programming_guide/index.html">Programming Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="kernel_language/index.html">Kernel Language</a></li>
<li class="toctree-l1"><a class="reference internal" href="comparison.html">Comparison with CUDA and other compute APIs</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Frequently Asked Questions (FAQ)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#what-apis-and-features-does-hip-support">What APIs and features does HIP support?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#what-is-not-supported">What is not supported?</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#runtime-driver-api-features">Runtime/Driver API features</a></li>
<li class="toctree-l3"><a class="reference internal" href="#kernel-language-features">Kernel language features</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#is-hip-a-drop-in-replacement-for-cuda">Is HIP a drop-in replacement for CUDA?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#what-specific-version-of-cuda-does-hip-support">What specific version of CUDA does HIP support?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#what-libraries-does-hip-support">What libraries does HIP support?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#how-does-hip-compare-with-opencl">How does HIP compare with OpenCL?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#how-does-porting-cuda-to-hip-compare-to-porting-cuda-to-opencl">How does porting CUDA to HIP compare to porting CUDA to OpenCL?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#what-hardware-does-hip-support">What hardware does HIP support?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#does-hipify-automatically-convert-all-source-code">Does Hipify automatically convert all source code?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#what-is-nvcc">What is NVCC?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#what-is-hcc">What is HCC?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#what-is-hip-clang">What is HIP-Clang?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#why-use-hip-rather-than-supporting-cuda-directly">Why use HIP rather than supporting CUDA directly?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#can-i-develop-hip-code-on-an-nvidia-cuda-platform">Can I develop HIP code on an Nvidia CUDA platform?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#can-i-develop-hip-code-on-an-amd-hip-clang-platform">Can I develop HIP code on an AMD HIP-Clang platform?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#do-i-need-to-make-code-changes-in-hip-code-if-switching-compiler-from-hcc-to-hip-clang">Do I need to make code changes in HIP code if switching compiler from HCC to HIP-Clang?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#how-to-use-hip-clang-to-build-hip-programs">How to use HIP-Clang to build HIP programs?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#what-is-rocclr">What is ROCclr?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#can-a-hip-binary-run-on-both-amd-and-nvidia-platforms">Can a HIP binary run on both AMD and NVIDIA platforms?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#what-s-the-difference-between-hip-and-hc">What’s the difference between HIP and HC?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#on-hip-clang-can-i-link-hip-code-with-host-code-compiled-with-another-compiler-such-as-gcc-icc-or-clang">On HIP-Clang, can I link HIP code with host code compiled with another compiler such as gcc, icc, or clang ?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#can-i-install-both-cuda-sdk-and-hip-clang-on-the-same-machine">Can I install both CUDA SDK and HIP-Clang on the same machine?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#hip-detected-my-platform-hip-clang-vs-nvcc-incorrectly-what-should-i-do">HIP detected my platform (HIP-Clang vs nvcc) incorrectly - what should I do?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#on-cuda-can-i-mix-cuda-code-with-hip-code">On CUDA, can I mix CUDA code with HIP code?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#on-hip-clang-can-i-use-hc-functionality-with-hip">On HIP-Clang, can I use HC functionality with HIP?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#how-do-i-trace-hip-application-flow">How do I trace HIP application flow?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#what-if-hip-generates-error-of-symbol-multiply-defined-only-on-the-amd-machine">What if HIP generates error of symbol multiply defined only on the AMD machine?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#what-is-maximum-limit-of-kernel-launching-parameter">What is maximum limit of kernel launching parameter?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#are-shfl-sync-functions-supported-on-hip-platform">Are <code class="docutils literal notranslate"><span class="pre">__shfl_*_sync</span></code> functions supported on HIP platform?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="repository_information.html">Repository Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="depreciated.html">HIP Deprecated APIs</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">HIP</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Frequently Asked Questions (FAQ)</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/faq.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="frequently-asked-questions-faq">
<h1>Frequently Asked Questions (FAQ)<a class="headerlink" href="#frequently-asked-questions-faq" title="Permalink to this headline">¶</a></h1>
<div class="section" id="what-apis-and-features-does-hip-support">
<h2>What APIs and features does HIP support?<a class="headerlink" href="#what-apis-and-features-does-hip-support" title="Permalink to this headline">¶</a></h2>
<p>HIP provides the following:</p>
<ul class="simple">
<li><p>Devices: (<code class="docutils literal notranslate"><span class="pre">hipSetDevice()</span></code>, <code class="docutils literal notranslate"><span class="pre">hipGetDeviceProperties()</span></code>, etc.)</p></li>
<li><p>Memory management (<code class="docutils literal notranslate"><span class="pre">hipMalloc()</span></code>, <code class="docutils literal notranslate"><span class="pre">hipMemcpy()</span></code>, <code class="docutils literal notranslate"><span class="pre">hipFree()</span></code>, etc)</p></li>
<li><p>Streams (<code class="docutils literal notranslate"><span class="pre">hipStreamCreate()</span></code>, <code class="docutils literal notranslate"><span class="pre">hipStreamSynchronize()</span></code>, <code class="docutils literal notranslate"><span class="pre">hipStreamWaitEvent()</span></code>,  etc.)</p></li>
<li><p>Events (<code class="docutils literal notranslate"><span class="pre">hipEventRecord()</span></code>, <code class="docutils literal notranslate"><span class="pre">hipEventElapsedTime()</span></code>, etc.)</p></li>
<li><p>Kernel launching (<code class="docutils literal notranslate"><span class="pre">hipLaunchKernelGGL</span></code> is a standard C/C++ function that replaces &lt;&lt;&lt; &gt;&gt;&gt;)</p></li>
<li><p>HIP Module API to control when adn how code is loaded.</p></li>
<li><p>CUDA-style kernel coordinate functions (<code class="docutils literal notranslate"><span class="pre">threadIdx</span></code>, <code class="docutils literal notranslate"><span class="pre">blockIdx</span></code>, <code class="docutils literal notranslate"><span class="pre">blockDim</span></code>, <code class="docutils literal notranslate"><span class="pre">gridDim</span></code>)</p></li>
<li><p>Cross-lane instructions including <code class="docutils literal notranslate"><span class="pre">shfl</span></code>, <code class="docutils literal notranslate"><span class="pre">ballot</span></code>, <code class="docutils literal notranslate"><span class="pre">any</span></code>, <code class="docutils literal notranslate"><span class="pre">all</span></code></p></li>
<li><p>Most device-side math built-ins</p></li>
<li><p>Error reporting (<code class="docutils literal notranslate"><span class="pre">hipGetLastError()</span></code>, <code class="docutils literal notranslate"><span class="pre">hipGetErrorString()</span></code>)</p></li>
</ul>
<p>The HIP API documentation describes each API and its limitations, if any,
compared with the equivalent CUDA API.</p>
</div>
<div class="section" id="what-is-not-supported">
<h2>What is not supported?<a class="headerlink" href="#what-is-not-supported" title="Permalink to this headline">¶</a></h2>
<div class="section" id="runtime-driver-api-features">
<h3>Runtime/Driver API features<a class="headerlink" href="#runtime-driver-api-features" title="Permalink to this headline">¶</a></h3>
<p>At a high level, the following features are not supported:</p>
<ul class="simple">
<li><p>Textures</p></li>
<li><p>Dynamic parallelism (CUDA 5.0)</p></li>
<li><p>Managed memory (CUDA 6.5)</p></li>
<li><p>Graphics interoperability with OpenGL or Direct3D</p></li>
<li><p>CUDA Driver API</p></li>
<li><p>CUDA IPC Functions (Under Development)</p></li>
<li><p>CUDA array, mipmappedArray and pitched memory</p></li>
<li><p>MemcpyToSymbol functions</p></li>
<li><p>Queue priority controls</p></li>
</ul>
<p>See the [API Support Table](CUDA_Runtime_API_functions_supported_by_HIP.md) for more detailed information.</p>
</div>
<div class="section" id="kernel-language-features">
<h3>Kernel language features<a class="headerlink" href="#kernel-language-features" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Device-side dynamic memory allocations (<code class="docutils literal notranslate"><span class="pre">malloc</span></code>, <code class="docutils literal notranslate"><span class="pre">free</span></code>,
<code class="docutils literal notranslate"><span class="pre">new</span></code>, <code class="docutils literal notranslate"><span class="pre">delete</span></code>) (CUDA 4.0)</p></li>
<li><p>Virtual functions, indirect functions and try/catch (CUDA 4.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">__prof_trigger</span></code></p></li>
<li><p>PTX assembly (CUDA 4.0).  HCC supports inline GCN assembly.</p></li>
<li><p>Several kernel features are under development. See the
<a class="reference external" href="hip_kernel_language.md">HIP Kernel Language</a> for more information.</p></li>
</ul>
<p>These include</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">printf</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">assert</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">__restrict__</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">__threadfence-_</span></code>, <code class="docutils literal notranslate"><span class="pre">__syncthreads*</span></code></p></li>
<li><p>Unbounded loop unroll</p></li>
</ul>
</div>
</div>
<div class="section" id="is-hip-a-drop-in-replacement-for-cuda">
<h2>Is HIP a drop-in replacement for CUDA?<a class="headerlink" href="#is-hip-a-drop-in-replacement-for-cuda" title="Permalink to this headline">¶</a></h2>
<p>No. HIP provides porting tools which do most of the work to convert CUDA code
into portable C++ code that uses the HIP APIs. Most developers will port their
code from CUDA to HIP and then maintain the HIP version. HIP code provides the
same performance as native CUDA code, plus the benefits of running on AMD
platforms.</p>
</div>
<div class="section" id="what-specific-version-of-cuda-does-hip-support">
<h2>What specific version of CUDA does HIP support?<a class="headerlink" href="#what-specific-version-of-cuda-does-hip-support" title="Permalink to this headline">¶</a></h2>
<p>HIP APIs and features do not map to a specific CUDA version. HIP provides a
strong subset of functionality provided in CUDA, and the hipify tools can scan
code to identify any unsupported CUDA functions. This is useful for
identifying the specific features required by a given application.</p>
<p>However, we can provide a rough summary of the features included in each CUDA
SDK and the support level in HIP:</p>
<ul class="simple">
<li><dl class="simple">
<dt>CUDA 4.0 and earlier</dt><dd><ul>
<li><p>HIP supports CUDA 4.0 except for the limitations described above.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>CUDA 5.0</dt><dd><ul>
<li><p>Dynamic Parallelism (not supported)</p></li>
<li><p>cuIpc functions (under development).</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>CUDA 5.5</dt><dd><ul>
<li><p>CUPTI (not directly supported), <a class="reference external" href="http://developer.amd.com/tools-and-sdks/graphics-development/gpuperfapi/">AMD GPUPerfAPI</a> can be used as an alternative in some cases)</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>CUDA 6.0</dt><dd><ul>
<li><p>Managed memory (under development)</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>CUDA 6.5</dt><dd><ul>
<li><p>__shfl instriniscs (supported)</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>CUDA 7.0</dt><dd><ul>
<li><p>Per-thread-streams (under development)</p></li>
<li><p>C++11 (HCC supports all of C++11, all of C++14 and some C++17 features)</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>CUDA 7.5</dt><dd><ul>
<li><p>float16</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>CUDA 8.0</dt><dd><ul>
<li><p>TBD.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</div>
<div class="section" id="what-libraries-does-hip-support">
<h2>What libraries does HIP support?<a class="headerlink" href="#what-libraries-does-hip-support" title="Permalink to this headline">¶</a></h2>
<p>HIP includes growing support for the 4 key math libraries using <code class="docutils literal notranslate"><span class="pre">hcBlas</span></code>,
<code class="docutils literal notranslate"><span class="pre">hcFft</span></code>, <code class="docutils literal notranslate"><span class="pre">hcrng</span></code> and <code class="docutils literal notranslate"><span class="pre">hcsparse</span></code>. These offer pointer-based memory
interfaces (as opposed to opaque buffers) and can be easily interfaced with
other HCC applications. Developers should use conditional compilation if
portability to nvcc systems is desired * using calls to <code class="docutils literal notranslate"><span class="pre">cu*</span></code> routines on
one path and <code class="docutils literal notranslate"><span class="pre">hc*</span></code> routines on the other.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/ROCmSoftwarePlatform/rocBLAS">rocblas</a></p></li>
<li><p><a class="reference external" href="https://github.com/ROCmSoftwarePlatform/rocFFT">rocfft</a></p></li>
<li><p><a class="reference external" href="https://github.com/ROCmSoftwarePlatform/MIOpen">MIOpen</a></p></li>
<li><p>hipRAND Under Development</p></li>
</ul>
<p>Additionally, some of the cublas routines are automatically converted to
hipblas equivalents by the hipify-clang tool.  These APIs use cublas or hcblas
depending on the platform, and replace the need to use conditional
compilation.</p>
</div>
<div class="section" id="how-does-hip-compare-with-opencl">
<h2>How does HIP compare with OpenCL?<a class="headerlink" href="#how-does-hip-compare-with-opencl" title="Permalink to this headline">¶</a></h2>
<p>Both AMD and Nvidia support OpenCL 1.2 on their devices, so developers can
write portable code. HIP offers several benefits over OpenCL:</p>
<ul class="simple">
<li><p>Developers can code in C++ as well as mix host and device C++ code in their
source files. HIP C++ code can use templates, lambdas, classes and so on.</p></li>
<li><p>The HIP API is less verbose than OpenCL and is familiar to CUDA developers.</p></li>
<li><p>Because both CUDA and HIP are C++ languages, porting from CUDA to HIP is
significantly easier than porting from CUDA to OpenCL.</p></li>
<li><p>HIP uses the best available development tools on each platform: on
Nvidia GPUs, HIP code compiles using NVCC and can employ the nSight profiler
and debugger (unlike OpenCL on Nvidia GPUs).</p></li>
<li><p>HIP provides pointers and host-side pointer arithmetic.</p></li>
<li><p>HIP provides device-level control over memory allocation and placement.</p></li>
<li><p>HIP offers an offline compilation model.</p></li>
</ul>
</div>
<div class="section" id="how-does-porting-cuda-to-hip-compare-to-porting-cuda-to-opencl">
<h2>How does porting CUDA to HIP compare to porting CUDA to OpenCL?<a class="headerlink" href="#how-does-porting-cuda-to-hip-compare-to-porting-cuda-to-opencl" title="Permalink to this headline">¶</a></h2>
<p>Both HIP and CUDA are dialects of C++, and thus porting between them is
relatively straightforward. Both dialects support templates, classes, lambdas,
and other C++ constructs.</p>
<p>As one example, the hipify tool was originally a Perl script that used simple
text conversions from CUDA to HIP. HIP and CUDA provide similar math library
calls as well. In summary, the HIP philosophy was to make the HIP language
close enough to CUDA that the porting effort is relatively simple.</p>
<p>This reduces the potential for error, and also makes it easy to automate the
translation.  HIP’s goal is to quickly get the ported program running on both
platforms with little manual intervention, so that the programmer can focus on
performance optimizations.</p>
<p>There have been several tools that have attempted to convert CUDA into OpenCL,
such as CU2CL.  OpenCL is a C99-based kernel language (rather than C++) and
also does not support single-source compilation. As a result, the OpenCL
syntax is different from CUDA, and the porting tools have to perform some
heroic transformations to bridge this gap. The tools also struggle with more
complex CUDA applications, in particular those that use templates, classes, or
other C++ features inside the kernel.</p>
</div>
<div class="section" id="what-hardware-does-hip-support">
<h2>What hardware does HIP support?<a class="headerlink" href="#what-hardware-does-hip-support" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>For AMD platforms, HIP runs on the same hardware that the HCC “hc” mode
supports.  See the ROCm documentation for the list of supported platforms.</p></li>
<li><p>For Nvidia platforms, HIP requires Unified Memory and should run on any
device supporting CUDA SDK 6.0 or newer. We have tested the Nvidia Titan and
Tesla K40.</p></li>
</ul>
</div>
<div class="section" id="does-hipify-automatically-convert-all-source-code">
<h2>Does Hipify automatically convert all source code?<a class="headerlink" href="#does-hipify-automatically-convert-all-source-code" title="Permalink to this headline">¶</a></h2>
<p>Typically, hipify can automatically convert almost all run-time code, and the
coordinate indexing device code ( <code class="docutils literal notranslate"><span class="pre">threadIdx.x</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">hipThreadIdx_x</span></code> ).</p>
<p>Most device code needs no additional conversion, since HIP and CUDA have
similar names for math and built-in functions. The <code class="docutils literal notranslate"><span class="pre">hipify-clang</span></code> tool will
automatically modify the kernel signature as needed (automating a step that
used to be done manually)</p>
<p>Additional porting may be required to deal with architecture feature queries
or with CUDA capabilities that HIP doesn’t support. In general, developers
should always expect to perform some platform-specific tuning and
optimization.</p>
</div>
<div class="section" id="what-is-nvcc">
<h2>What is NVCC?<a class="headerlink" href="#what-is-nvcc" title="Permalink to this headline">¶</a></h2>
<p>NVCC is Nvidia’s compiler driver for compiling “CUDA C++” code into PTX or
device code for Nvidia GPUs. It’s a closed-source binary compiler that is
provided by the CUDA SDK.</p>
</div>
<div class="section" id="what-is-hcc">
<h2>What is HCC?<a class="headerlink" href="#what-is-hcc" title="Permalink to this headline">¶</a></h2>
<p>HCC is AMD’s compiler driver which compiles “heterogeneous C++” code into
HSAIL or GCN device code for AMD GPUs.  It’s an open-source compiler based on
recent versions of CLANG/LLVM.</p>
</div>
<div class="section" id="what-is-hip-clang">
<h2>What is HIP-Clang?<a class="headerlink" href="#what-is-hip-clang" title="Permalink to this headline">¶</a></h2>
<p>HIP-Clang is new compiler to emphasize its capability to compile HIP
programs which can run on AMD platform.</p>
</div>
<div class="section" id="why-use-hip-rather-than-supporting-cuda-directly">
<h2>Why use HIP rather than supporting CUDA directly?<a class="headerlink" href="#why-use-hip-rather-than-supporting-cuda-directly" title="Permalink to this headline">¶</a></h2>
<p>While HIP is a strong subset of the CUDA, it is a subset. The HIP layer
allows that subset to be clearly defined and documented.</p>
<p>Developers who code to the HIP API can be assured their code will remain
portable across Nvidia and AMD platforms. In addition, HIP defines portable
mechanisms to query architectural features, and supports a larger 64-bit
wavesize which expands the return type for cross-lane functions like ballot
and shuffle from 32-bit ints to 64-bit ints.</p>
</div>
<div class="section" id="can-i-develop-hip-code-on-an-nvidia-cuda-platform">
<h2>Can I develop HIP code on an Nvidia CUDA platform?<a class="headerlink" href="#can-i-develop-hip-code-on-an-nvidia-cuda-platform" title="Permalink to this headline">¶</a></h2>
<p>Yes. HIP’s CUDA path only exposes the APIs and functionality that work on
both NVCC and HCC back-ends. “Extra” APIs, parameters, and features which
exist in CUDA but not in HCC will typically result in compile- or run-time
errors.</p>
<p>Developers need to use the HIP API for most accelerator code, and bracket any
CUDA-specific code with preprocessor conditionals.</p>
<p>Developers concerned about portability should of course run on both platforms,
and should expect to tune for performance. In some cases CUDA has a richer set
of modes for some APIs, and some C++ capabilities such as virtual functions.
see the HIP &#64;API documentation for more details.</p>
</div>
<div class="section" id="can-i-develop-hip-code-on-an-amd-hip-clang-platform">
<h2>Can I develop HIP code on an AMD HIP-Clang platform?<a class="headerlink" href="#can-i-develop-hip-code-on-an-amd-hip-clang-platform" title="Permalink to this headline">¶</a></h2>
<p>Yes. HIP-Clang path only exposes the APIs and functions that work on AMD
runtime back ends. APIs, parameters, and features that appear in HIP-Clang
but not CUDA will typically cause compile or run-time errors. Developers
must use the HIP API for most accelerator code and bracket any HIP-Clang
specific code with preprocessor conditionals. Those concerned about
portability should, of course, test their code on both platforms and should
tune it for performance.</p>
<p>Typically, HIP-Clang supports a more modern set of C++11/C++14/C++17
features, so HIP developers who want portability should be careful when
using advanced C++ features on the HIP-Clang path. In ROCM v3.5 release, HCC
compiler is deprecated, and the HIP-Clang compiler can be used for compiling
HIP programs.</p>
</div>
<div class="section" id="do-i-need-to-make-code-changes-in-hip-code-if-switching-compiler-from-hcc-to-hip-clang">
<h2>Do I need to make code changes in HIP code if switching compiler from HCC to HIP-Clang?<a class="headerlink" href="#do-i-need-to-make-code-changes-in-hip-code-if-switching-compiler-from-hcc-to-hip-clang" title="Permalink to this headline">¶</a></h2>
<p>For most HIP applications, the transition from HCC to HIP-Clang is
transparent as the HIPCC and HIP cmake files automatically choose compiler
options for HIP-Clang and hide the difference between the HCC and HIP-Clang
code. However, minor changes may be required as HIP-Clang has stricter
syntax and semantic checks compared to HCC.</p>
</div>
<div class="section" id="how-to-use-hip-clang-to-build-hip-programs">
<h2>How to use HIP-Clang to build HIP programs?<a class="headerlink" href="#how-to-use-hip-clang-to-build-hip-programs" title="Permalink to this headline">¶</a></h2>
<p>The environment variable can be used to set compiler path:</p>
<ul class="simple">
<li><p>HIP_CLANG_PATH: path to hip-clang. When set, this variable let hipcc to
use hip-clang for compilation/linking.</p></li>
</ul>
<p>There is an alternative environment variable to set compiler path:</p>
<ul class="simple">
<li><p>HIP_ROCCLR_HOME: path to root directory of the HIP-ROCclr runtime.
When set, this variable let hipcc use hip-clang from the ROCclr
distribution.</p></li>
</ul>
<p>NOTE: If HIP_ROCCLR_HOME is set, there is no need to set HIP_CLANG_PATH
since hipcc will deduce them from HIP_ROCCLR_HOME.</p>
</div>
<div class="section" id="what-is-rocclr">
<h2>What is ROCclr?<a class="headerlink" href="#what-is-rocclr" title="Permalink to this headline">¶</a></h2>
<p>ROCclr (Radeon Open Compute Common Language Runtime) is a virtual device
interface that compute runtimes interact with backends such as ROCr on Linux,
as well as PAL on Windows.</p>
</div>
<div class="section" id="can-a-hip-binary-run-on-both-amd-and-nvidia-platforms">
<h2>Can a HIP binary run on both AMD and NVIDIA platforms?<a class="headerlink" href="#can-a-hip-binary-run-on-both-amd-and-nvidia-platforms" title="Permalink to this headline">¶</a></h2>
<p>HIP is a source-portable language that can be compiled to run on either AMD
or NVIDIA platform. HIP tools don’t create a fat binary that can
run on either platform.</p>
</div>
<div class="section" id="what-s-the-difference-between-hip-and-hc">
<h2>What’s the difference between HIP and HC?<a class="headerlink" href="#what-s-the-difference-between-hip-and-hc" title="Permalink to this headline">¶</a></h2>
<p>HIP is a portable C++ language that supports a strong subset of the CUDA
run-time APIs and device-kernel language. It is designed to simplify CUDA
conversion to portable C++. HIP provides a C-compatible run-time API,
C-compatible kernel-launch mechanism, C++ kernel language and pointer-based
memory management.</p>
<p>A C++ dialect, hc is supported by the AMD compiler. It provides C++ run
time, C++ kernel-launch APIs (parallel_for_each), C++ kernel language, and
several memory-management options, including pointers, arrays and array_view
(with implicit data synchronization). It is intended to be a leading
indicator of the ISO C++ standard. The HCC compiler has been deprecated in
the ROCm Release v3.5.</p>
</div>
<div class="section" id="on-hip-clang-can-i-link-hip-code-with-host-code-compiled-with-another-compiler-such-as-gcc-icc-or-clang">
<h2>On HIP-Clang, can I link HIP code with host code compiled with another compiler such as gcc, icc, or clang ?<a class="headerlink" href="#on-hip-clang-can-i-link-hip-code-with-host-code-compiled-with-another-compiler-such-as-gcc-icc-or-clang" title="Permalink to this headline">¶</a></h2>
<p>Yes. HIP generates the object code which conforms to the GCC ABI, and also
links with libstdc++. This means you can compile host code with the compiler
of your choice and link the generated object code with GPU code compiled
with HIP. Larger projects often contain a mixture of accelerator code
(initially written in CUDA with nvcc) and host code (compiled with gcc, icc,
or clang). These projects can convert the accelerator code to HIP, compile
that code with hipcc, and link with object code from their preferred
compiler.</p>
</div>
<div class="section" id="can-i-install-both-cuda-sdk-and-hip-clang-on-the-same-machine">
<h2>Can I install both CUDA SDK and HIP-Clang on the same machine?<a class="headerlink" href="#can-i-install-both-cuda-sdk-and-hip-clang-on-the-same-machine" title="Permalink to this headline">¶</a></h2>
<p>Yes. You can use HIP_PLATFORM to choose which path hipcc targets. This
configuration can be useful when using HIP to develop an application which
is portable to both AMD and NVIDIA.</p>
</div>
<div class="section" id="hip-detected-my-platform-hip-clang-vs-nvcc-incorrectly-what-should-i-do">
<h2>HIP detected my platform (HIP-Clang vs nvcc) incorrectly - what should I do?<a class="headerlink" href="#hip-detected-my-platform-hip-clang-vs-nvcc-incorrectly-what-should-i-do" title="Permalink to this headline">¶</a></h2>
<p>HIP will set the platform to hcc and compiler to HIP-Clang if it sees that
the AMD graphics driver is installed and has detected an AMD GPU. If this is
not what you want, you can force HIP to recognize the platform by setting
the following,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">export</span> <span class="n">HIP_COMPILER</span><span class="o">=</span><span class="n">clang</span>
<span class="n">export</span> <span class="n">HIP_PLATFORM</span><span class="o">=</span><span class="n">hcc</span>
</pre></div>
</div>
<p>One symptom of this problem is the error message: ‘an unknown error(11)
at square.hipref.cpp:56’.</p>
<p>This can occur if you have a CUDA installation on an AMD platform, and HIP
incorrectly detects the platform as nvcc. HIP may be able to compile the
application using the nvcc tool-chain but will generate this error at
runtime since the platform does not have a CUDA device. The fix is to set
HIP_PLATFORM=hcc and rebuild.</p>
</div>
<div class="section" id="on-cuda-can-i-mix-cuda-code-with-hip-code">
<h2>On CUDA, can I mix CUDA code with HIP code?<a class="headerlink" href="#on-cuda-can-i-mix-cuda-code-with-hip-code" title="Permalink to this headline">¶</a></h2>
<p>Yes. Most HIP data structures (hipStream_t, hipEvent_t) are typedefs to CUDA
equivalents and can be intermixed. Both CUDA and HIP use integer device ids.
One notable exception is that hipError_t is a new type, and cannot be used
where a cudaError_t is expected. In these cases, refactor the code to remove
the expectation. Alternatively, hip_runtime_api.h defines functions which
convert between the error code spaces:</p>
<p>hipErrorToCudaError hipCUDAErrorTohipError hipCUResultTohipError</p>
<p>If platform portability is important, use #ifdef <strong>HIP_PLATFORM_NVCC</strong> to
guard the CUDA-specific code.</p>
</div>
<div class="section" id="on-hip-clang-can-i-use-hc-functionality-with-hip">
<h2>On HIP-Clang, can I use HC functionality with HIP?<a class="headerlink" href="#on-hip-clang-can-i-use-hc-functionality-with-hip" title="Permalink to this headline">¶</a></h2>
<p>No. HC functionality is not supported by HIP-Clang.</p>
</div>
<div class="section" id="how-do-i-trace-hip-application-flow">
<h2>How do I trace HIP application flow?<a class="headerlink" href="#how-do-i-trace-hip-application-flow" title="Permalink to this headline">¶</a></h2>
<p>See the <a class="reference external" href="hip_porting_guide.md">HIP Profiling Guide</a> for more information.</p>
</div>
<div class="section" id="what-if-hip-generates-error-of-symbol-multiply-defined-only-on-the-amd-machine">
<h2>What if HIP generates error of symbol multiply defined only on the AMD machine?<a class="headerlink" href="#what-if-hip-generates-error-of-symbol-multiply-defined-only-on-the-amd-machine" title="Permalink to this headline">¶</a></h2>
<p>Unlike CUDA, in HCC, for functions defined in the header files, the keyword
of “forceinline” does not imply “static”. Thus, if failed to define “static”
keyword, you might see a lot of “symbols that multiply defined” errors at
compilation. The workaround is to explicitly add the keyword of “static”
before any functions that were defined as “forceinline”.</p>
</div>
<div class="section" id="what-is-maximum-limit-of-kernel-launching-parameter">
<h2>What is maximum limit of kernel launching parameter?<a class="headerlink" href="#what-is-maximum-limit-of-kernel-launching-parameter" title="Permalink to this headline">¶</a></h2>
<p>Product of block.x, block.y, and block.z should be less than 1024.</p>
</div>
<div class="section" id="are-shfl-sync-functions-supported-on-hip-platform">
<h2>Are <code class="docutils literal notranslate"><span class="pre">__shfl_*_sync</span></code> functions supported on HIP platform?<a class="headerlink" href="#are-shfl-sync-functions-supported-on-hip-platform" title="Permalink to this headline">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">__shfl_*_sync</span></code> is not supported on HIP but for nvcc path CUDA 9.0 and above
all shuffle calls get redirected to its sync version.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="repository_information.html" class="btn btn-neutral float-right" title="Repository Information" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="comparison.html" class="btn btn-neutral float-left" title="Comparison with CUDA and other compute APIs" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Open GPU Compute

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>